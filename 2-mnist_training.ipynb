{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural Network Hands-On Tutorial Part 2\n",
    "\n",
    "## MNIST Classification Task"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Set device (GPU if available, else CPU)\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading the MNIST Dataset\n",
    "\n",
    "`torchvision` provides many built-in datasets, which are common benchmarks and can be used for learning purposes and drafting your own neural network implementations.\n",
    "\n",
    "Run the next cell to download the MNIST dataset and store it to the `./data` folder.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Looking at the Dataset\n",
    "\n",
    "The MNIST train dataset contains 60,000 pairs of data in the shape of (image, label).\n",
    "\n",
    "Each image is a grayscale image cropped to 28*28 pixels, with a centered handwritten digit.\n",
    "\n",
    "_Note_: the test dataset contains 10,000 images with the same shape as the train data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000\n",
      "(<PIL.Image.Image image mode=L size=28x28 at 0x1470FA1D0>, 5)\n"
     ]
    }
   ],
   "source": [
    "print(len(train_dataset))\n",
    "print(train_dataset[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x250 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "idx = 0  # Change the index to see different images\n",
    "\n",
    "# Show some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(7, 2.5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(train_dataset[i+idx][0], cmap='gray')\n",
    "    axes[i].set_title(f\"label: {train_dataset[i+idx][1]}\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Currently, the images are `PIL` images and the amplitudes range from 0 to 255."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "255 0 (28, 28)\n"
     ]
    }
   ],
   "source": [
    "img = train_dataset[0][0]\n",
    "print(np.max(img), np.min(img), np.shape(img))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "\n",
    "In order to train a neural network with the dataset, the train dataset needs to be pre-processed. In `PyTorch` and `torchvision`, this can be achieved by `torchvision.transforms`, which includes many common image processing methods.\n",
    "\n",
    "Note that the images in the MNIST dataset are already _centered_ and _cropped to the same shape_. (For your own dataset, remember to perform these steps.)\n",
    "\n",
    "We only need to perform two steps:\n",
    "\n",
    "1. Convert the PIL images with amplitude $[0,255]$ to PyTorch Tensors in $[0,1]$, with `transforms.ToTensor()`\n",
    "2. Normalize the images to $\\mu=0.5$ and $\\sigma=0.5$, with `transforms.Normalize()`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Multiple transformations can be chained by using `transforms.Compose`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_transform = transforms.Compose([\n",
    "    transforms.ToTensor(),  # Convert image to tensor\n",
    "    # transforms.Normalize((0.5,), (0.5,))  # Normalize image to mean 0.5 and std 0.5\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's define the train and test dataset again, with the proper transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=mnist_transform)\n",
    "test_dataset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=mnist_transform)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can load mini-batches of data from the dataset using `DataLoader`.\n",
    "\n",
    "Setting `shuffle=True` allows the batches to be sampled in a random order across different episodes. \n",
    "\n",
    "Why do we need it? $\\rightarrow$ Prevents converging into local optima and overfitting.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "batchsize = 64\n",
    "train_loader = DataLoader(dataset=train_dataset, batch_size=batchsize, shuffle=True)\n",
    "test_loader = DataLoader(dataset=test_dataset, batch_size=batchsize, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now look at one batch of data sampled from the `DataLoader`\n",
    "\n",
    "The input data shape would be: [batch_size, channel, height, width]. Here channel=1 because we are using grayscale images. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input batch shape:  torch.Size([64, 1, 28, 28])\n",
      "Output batch shape:  torch.Size([64])\n"
     ]
    }
   ],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "print(\"Input batch shape: \", images.shape)\n",
    "print(\"Output batch shape: \", labels.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network structure\n",
    "\n",
    "For the MNIST task, it is sufficient to use a small, fully-connected neural network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "class SimpleNN(nn.Module):\n",
    "    def __init__(self, input_size=28*28, num_classes=10, hidden_size=128):\n",
    "        super(SimpleNN, self).__init__()\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(input_size, hidden_size)\n",
    "        self.activation = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(hidden_size, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.flatten(x)\n",
    "        x = self.fc1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.fc2(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleNN(\n",
      "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "  (fc1): Linear(in_features=784, out_features=128, bias=True)\n",
      "  (activation): ReLU()\n",
      "  (fc2): Linear(in_features=128, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = SimpleNN().to(device)\n",
    "print(model) # Look at the model architecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the loss function\n",
    "\n",
    "Here we are dealing with a classification problem with 10 classes (digits from 0 to 9), which loss function should we use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Cross-entropy Loss**\n",
    "\n",
    "For one data pair $(x,y)$, the cross-entropy loss is calculated\n",
    "\n",
    "$$\n",
    "l_\\text{Cross-Entropy}(y,y') = - \\sum_{i=1}^{C} \\log \\frac{\\exp{y_i}}{\\sum_{c=1}^{C} \\exp{(y_{c})}} y'_{i},\n",
    "$$\n",
    "\n",
    "Here \n",
    "- $\\{1, \\dots, C=10 \\}$ class indices. \n",
    "- $y'$ is a one-hot vector, i.e. $y'_{i}=1$ if the ground truth label is class $i$. \n",
    "- $y$ is the output predicted by the neural network."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "\n",
    "- Note 1: The first part $\\exp{y_i}/\\sum_c\\exp{y_c}$ is a `Softmax` activation, mapping the unbounded outputs to probabilities between $[0,1]$.\n",
    "- Note 2: For the batched input, the loss is commonly averaged over the batches."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "criterion = nn.CrossEntropyLoss()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define an optimizer\n",
    "\n",
    "We can choose from the common optimizers, see [`torch.optim` documentation](https://pytorch.org/docs/stable/optim.html):\n",
    "- Stochastic gradient descent ([SGD](https://pytorch.org/docs/stable/generated/torch.optim.SGD.html#torch.optim.SGD)): `optim.SGD`\n",
    "- [Adam](https://pytorch.org/docs/stable/generated/torch.optim.Adam.html#torch.optim.Adam): `optim.Adam`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feel free to change the optimizer and its hyperparameters\n",
    "learning_rate = 1e-3\n",
    "optimizer = optim.Adam(model.parameters(), lr=learning_rate)  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_loader, criterion, optimizer, num_epochs=10):\n",
    "    model.train()  # Set the model to training mode\n",
    "    for epoch in range(num_epochs): # Loop through the dataset multiple epochs\n",
    "        for i, (images, labels) in enumerate(train_loader): # Loop through batches in the train loader\n",
    "            images, labels = images.to(device), labels.to(device) # Move data to device (GPU if available)\n",
    "            outputs = model(images) # Forward pass\n",
    "            loss = criterion(outputs, labels) # Compute loss\n",
    "\n",
    "            optimizer.zero_grad() # Prepare for backward pass\n",
    "            loss.backward() # Backward pass\n",
    "            optimizer.step() # Update model parameters\n",
    "\n",
    "            if (i+1) % 400 == 0:\n",
    "                print(f'Epoch [{epoch+1}/{num_epochs}], Step [{i+1}/{len(train_loader)}], Loss: {loss.item():.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Step [400/938], Loss: 0.2695\n",
      "Epoch [1/10], Step [800/938], Loss: 0.1714\n",
      "Epoch [2/10], Step [400/938], Loss: 0.1585\n",
      "Epoch [2/10], Step [800/938], Loss: 0.0839\n",
      "Epoch [3/10], Step [400/938], Loss: 0.0802\n",
      "Epoch [3/10], Step [800/938], Loss: 0.1878\n",
      "Epoch [4/10], Step [400/938], Loss: 0.0210\n",
      "Epoch [4/10], Step [800/938], Loss: 0.0512\n",
      "Epoch [5/10], Step [400/938], Loss: 0.0237\n",
      "Epoch [5/10], Step [800/938], Loss: 0.1229\n",
      "Epoch [6/10], Step [400/938], Loss: 0.0809\n",
      "Epoch [6/10], Step [800/938], Loss: 0.0892\n",
      "Epoch [7/10], Step [400/938], Loss: 0.0264\n",
      "Epoch [7/10], Step [800/938], Loss: 0.0085\n",
      "Epoch [8/10], Step [400/938], Loss: 0.0167\n",
      "Epoch [8/10], Step [800/938], Loss: 0.0160\n",
      "Epoch [9/10], Step [400/938], Loss: 0.0594\n",
      "Epoch [9/10], Step [800/938], Loss: 0.0239\n",
      "Epoch [10/10], Step [400/938], Loss: 0.0266\n",
      "Epoch [10/10], Step [800/938], Loss: 0.0220\n"
     ]
    }
   ],
   "source": [
    "train(model, train_loader, criterion, optimizer, num_epochs=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 97.67%\n"
     ]
    }
   ],
   "source": [
    "# Evaluation on the test set\n",
    "model.eval()\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "        outputs = model(images)\n",
    "        _, predicted = torch.max(outputs.data, 1)\n",
    "        total += labels.size(0)\n",
    "        correct += (predicted == labels).sum().item()\n",
    "\n",
    "accuracy = correct / total\n",
    "print(f\"Test Accuracy: {accuracy * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualize the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 700x250 with 5 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Redefine a loader to allow for visualization of random test images\n",
    "random_test_loader = DataLoader(dataset=test_dataset, batch_size=5, shuffle=True)\n",
    "\n",
    "images, labels = next(iter(random_test_loader))\n",
    "images, labels = images.to(device), labels.to(device)\n",
    "outputs = model(images)\n",
    "_, predictions = torch.max(outputs, 1)\n",
    "\n",
    "# Show some images\n",
    "fig, axes = plt.subplots(1, 5, figsize=(7, 2.5))\n",
    "for i in range(5):\n",
    "    axes[i].imshow(images[i][0], cmap='gray')\n",
    "    axes[i].set_title(f\"label: {labels[i]} \\n pred: {predictions[i]}\")\n",
    "    axes[i].axis('off')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's next\n",
    "\n",
    "Change the hyperparameters of the network, training process, and observe what will happen"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bonus\n",
    "\n",
    "Try a different network structure, which one would you use?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "new_rl",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
